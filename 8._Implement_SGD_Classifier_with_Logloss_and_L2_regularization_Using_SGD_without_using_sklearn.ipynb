{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eiDWcM_MC3H"
   },
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfe2NTQtLq11"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "# please don't change random_state\n",
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "# make_classification is used to create custom dataset \n",
    "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "L8W2fg1cyGdX",
    "outputId": "029d4c84-03b2-4143-a04c-34ff49c88890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "gONY1YiDq7jD"
   },
   "outputs": [],
   "source": [
    "# Standardizing the data.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "0DR_YMBsyOci",
    "outputId": "732014d9-1731-4d3f-918f-a9f5255ee149",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "id": "3HpvTwDHyQQy",
    "outputId": "5729f08c-079a-4b17-bf51-f9aeb5abb13b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "id": "YYaVyQ2lyXcr",
    "outputId": "dc0bf840-b37e-4552-e513-84b64f6c64c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.70, NNZs: 15, Bias: -0.501317, T: 37500, Avg. loss: 0.552526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.752393, T: 75000, Avg. loss: 0.448021\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.26, NNZs: 15, Bias: -0.902742, T: 112500, Avg. loss: 0.415724\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.43, NNZs: 15, Bias: -1.003816, T: 150000, Avg. loss: 0.400895\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.55, NNZs: 15, Bias: -1.076296, T: 187500, Avg. loss: 0.392879\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.65, NNZs: 15, Bias: -1.131077, T: 225000, Avg. loss: 0.388094\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.73, NNZs: 15, Bias: -1.171791, T: 262500, Avg. loss: 0.385077\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.80, NNZs: 15, Bias: -1.203840, T: 300000, Avg. loss: 0.383074\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.86, NNZs: 15, Bias: -1.229563, T: 337500, Avg. loss: 0.381703\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.90, NNZs: 15, Bias: -1.251245, T: 375000, Avg. loss: 0.380763\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.94, NNZs: 15, Bias: -1.269044, T: 412500, Avg. loss: 0.380084\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.98, NNZs: 15, Bias: -1.282485, T: 450000, Avg. loss: 0.379607\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2.01, NNZs: 15, Bias: -1.294386, T: 487500, Avg. loss: 0.379251\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 2.03, NNZs: 15, Bias: -1.305805, T: 525000, Avg. loss: 0.378992\n",
      "Total training time: 0.11 seconds.\n",
      "Convergence after 14 epochs took 0.11 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "EAfkVI6GyaRO",
    "outputId": "bc88f920-6531-4106-9b4c-4dabb6d72b47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.89007184,  0.63162363, -0.07594145,  0.63107107, -0.38434375,\n",
       "          0.93235243, -0.89573521, -0.07340522,  0.40591417,  0.4199991 ,\n",
       "          0.24722143,  0.05046199, -0.08877987,  0.54081652,  0.06643888]]),\n",
       " (1, 15),\n",
       " array([-1.30580538]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-CcGTKgsMrY"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1_8bdzitDlM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1.  We will be giving you some functions, please write code in that functions only.\n",
    "\n",
    "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zU2Y3-FQuJ3z"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    w = np.zeros_like(dim)\n",
    "    b = 0\n",
    "\n",
    "    #initialize the weights to zeros array of (1,dim) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "A7I6uWBRsKc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "w, b = initialize_weights(X_train[0])\n",
    "print('w =',(w))\n",
    "print('b =',str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MI5SAjP9ofN"
   },
   "source": [
    "<font color='cyan'>Grader function - 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Pv1llH429wG5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "\n",
    "def grader_weights(w,b):\n",
    "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
    "  return True\n",
    "grader_weights(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    sigm = 1 / (1 + np.exp(-z))\n",
    "    # compute sigmoid(z) and return\n",
    "\n",
    "    return sigm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YrGDwg3Ae4m"
   },
   "source": [
    "<font color='cyan'>Grader function - 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "P_JASp_NAfK_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "    val=sigmoid(z)\n",
    "    assert(val==0.8807970779778823)\n",
    "    return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "VaFDgsp3sKi6"
   },
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    sum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        sum += (y_true[i] * np.log10(y_pred[i])) + ((1 - y_true[i]) * np.log10(1 - y_pred[i]))\n",
    "    loss = -1 * (1 / len(y_true)) * sum\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs1BTXVSClBt"
   },
   "source": [
    "<font color='cyan'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "LzttjvBFCuQ5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_logloss(true,pred):\n",
    "    loss=logloss(true,pred)\n",
    "    assert(loss==0.07644900402910389)\n",
    "    return True\n",
    "\n",
    "true = np.array([1,1,0,1,0])\n",
    "pred = np.array([0.9,0.8,0.1,0.8,0.2])\n",
    "grader_logloss(true, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    dw = x*(y - sigmoid(np.dot(w.T,x) + b)) - ((alpha*w)).sum() / N\n",
    "\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUFLNqL_GER9"
   },
   "source": [
    "<font color='cyan'>Grader function - 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "WI3xD8ctGEnJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_dw(x,y,w,b,alpha,N):\n",
    "    grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
    "    assert(np.sum(grad_dw)==2.613689585)\n",
    "    return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    " def gradient_db(x,y,w,b):\n",
    "        '''In this function, we will compute gradient w.r.to b '''\n",
    "        db = y - sigmoid(np.dot(w.T, x) + b)\n",
    "        \n",
    "        return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbcBzufVG6qk"
   },
   "source": [
    "<font color='cyan'>Grader function - 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "TfFDKmscG5qZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x,y,w,b):\n",
    "  grad_db=gradient_db(x,y,w,b)\n",
    "  assert(grad_db==-0.5)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_db(grad_x,grad_y,grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
    "    \n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    #Here eta0 is learning rate\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    w, b = initialize_weights(X_train[0])\n",
    "    for i in range(epochs):\n",
    "        train_pred = []\n",
    "        test_pred = []\n",
    "        for j in range(N):\n",
    "            dw = gradient_dw(X_train[j],y_train[j],w,b,alpha,N)\n",
    "            db = gradient_db(X_train[j],y_train[j],w,b)\n",
    "            w = w + (eta0 * dw)\n",
    "            b = b + (eta0 * db)\n",
    "        for val in range(N):\n",
    "            train_pred.append(sigmoid(np.dot(w, X_train[val]) + b))\n",
    "            \n",
    "        loss1 = logloss(y_train, train_pred)\n",
    "        train_loss.append(loss1)\n",
    "            \n",
    "        for val in range(len(X_test)):\n",
    "            test_pred.append(sigmoid(np.dot(w, X_test[val]) + b))\n",
    "            \n",
    "        loss2 = logloss(y_test, test_pred)\n",
    "        test_loss.append(loss2)\n",
    "        \n",
    "    return w,b,train_loss,test_loss     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "sUquz7LFEZ6E"
   },
   "outputs": [],
   "source": [
    "alpha=0.0001\n",
    "eta0=0.0001\n",
    "N=len(X_train)\n",
    "epochs=14\n",
    "w,b,train_log_loss,test_log_loss=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.89482333,  0.63922611, -0.07409047,  0.63113616, -0.3827988 ,\n",
       "         0.93469327, -0.89664523, -0.0712441 ,  0.41113383,  0.4155007 ,\n",
       "         0.24845753,  0.05300599, -0.0870303 ,  0.53952882,  0.06749244]),\n",
       " -1.303005862472513)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "<font color='red'>Goal of assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "nx8Rs9rfEZ1R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-4.75149326e-03,  7.60248366e-03,  1.85097969e-03,\n",
       "          6.50866971e-05,  1.54494847e-03,  2.34083047e-03,\n",
       "         -9.10016289e-04,  2.16111322e-03,  5.21965791e-03,\n",
       "         -4.49839833e-03,  1.23610435e-03,  2.54400322e-03,\n",
       "          1.74956320e-03, -1.28769913e-03,  1.05355585e-03]]),\n",
       " array([0.00279952]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "w-clf.coef_, b-clf.intercept_\n",
    "# if you hard check it, it's 0.004 approx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
    "\n",
    "* epoch number on X-axis\n",
    "* loss on Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "1O6GrRt7UeCJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "epoch = [i for i in range(1,15,1)]\n",
    "\n",
    "plt.plot(epoch,train_log_loss , label='train_log_loss')\n",
    "plt.plot(epoch,test_log_loss, label='test_log_loss')\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"log-loss\")\n",
    "plt.title('Number of epochs vs. loss')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "FUN8puFoEZtU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9505866666666667\n",
      "0.9476\n"
     ]
    }
   ],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
    "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
